{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating protocol files for the paper &darr;\n",
    "### The Overlooked Elephant of Object Detection: Open Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first map all COCO objects to their corresponding PASCAL VOC objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "COCOID_to_pascalID = {\n",
    "                        5: 1,\n",
    "                        2: 2,\n",
    "                        16: 3,\n",
    "                        9: 4,\n",
    "                        44: 5,\n",
    "                        6: 6,\n",
    "                        3: 7,\n",
    "                        17: 8,\n",
    "                        62: 9,\n",
    "                        21: 10,\n",
    "                        67: 11,\n",
    "                        18: 12,\n",
    "                        19: 13,\n",
    "                        4: 14,\n",
    "                        1: 15,\n",
    "                        64: 16,\n",
    "                        20: 17,\n",
    "                        63: 18,\n",
    "                        7: 19,\n",
    "                        72: 20\n",
    "                    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "coco_ids, pascal_ids = zip(*COCOID_to_pascalID.items())\n",
    "PascalID_to_COCOID = dict(zip(pascal_ids,coco_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necessary Imports\n",
    "import json\n",
    "from pycocotools.coco import COCO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The protocol in this paper is based on the PASCAL VOC and the MSCOCO dataset\n",
    "\n",
    "Please define their paths below along with the expected openset protocol file names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "coco_2017_training_file = 'instances_train2017.json'\n",
    "pascal_2007_test_file = 'pascal_test2007.json'\n",
    "mixed_unknowns_file_name = \"Mixed_Unknowns.json\"\n",
    "WR1_mixed_unknowns_file_name = \"WR1_Mixed_Unknowns.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the files into coco objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=54.78s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.42s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "coco_2017_train=COCO(coco_2017_training_file)\n",
    "pascal_2007_test=COCO(pascal_2007_test_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating category mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories_info=[]\n",
    "COCO_new_class_id_mapping={}\n",
    "PASCAL_new_class_id_mapping={}\n",
    "for new_class_id,(COCO_ID,PASCAL_ID) in enumerate(COCOID_to_pascalID.items(), start=1):\n",
    "    COCO_new_class_id_mapping[COCO_ID] = new_class_id\n",
    "    PASCAL_new_class_id_mapping[PASCAL_ID] = new_class_id\n",
    "    categories_info.append(pascal_2007_test.cats[PASCAL_ID])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_categories_info = categories_info[:]\n",
    "test_categories_info.append({'supercategory': 'none', 'id': -1, 'name': 'unknown'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making the protocol for only knowns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pascal_to_custom_training_protcol(input_file_name,output_file_name, testing_cats=False):\n",
    "    coco_obj = COCO('original_protocols/'+input_file_name)\n",
    "    json_data = coco_obj.dataset.copy()\n",
    "    new_json = {}\n",
    "    new_json['images']=[]\n",
    "    new_json['annotations']=[]\n",
    "    if testing_cats:\n",
    "        new_json['categories']=test_categories_info[:]\n",
    "    else:\n",
    "        new_json['categories']=categories_info[:]\n",
    "    \n",
    "    for img_id in coco_obj.imgs.keys():\n",
    "        new_json['images'].append(coco_obj.imgs[img_id])\n",
    "        ann_ids = coco_obj.getAnnIds(imgIds=[img_id])\n",
    "        for annotation in coco_obj.loadAnns(ids=ann_ids):\n",
    "            annotation['category_id'] = PASCAL_new_class_id_mapping[annotation['category_id']]\n",
    "            del annotation['ignore']\n",
    "            new_json['annotations'].append(annotation)\n",
    "    json.dump(new_json, open('custom_protocols/'+output_file_name, \"w\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.13s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.13s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.28s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.24s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.26s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "pascal_orignal_files = ('voc_2007_train.json','voc_2007_val.json','voc_2012_train.json','voc_2012_val.json')\n",
    "updated_files = ['custom_'+_ for _ in pascal_orignal_files]\n",
    "for input_file_name,output_file_name in zip(pascal_orignal_files,updated_files):\n",
    "    pascal_to_custom_training_protcol(input_file_name,output_file_name)\n",
    "pascal_to_custom_training_protcol('voc_2007_test.json','custom_voc_2007_test.json', testing_cats=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making the protocol for mixed unknowns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding images that donot contain any of the known objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_with_knowns=[]\n",
    "for _ in COCOID_to_pascalID.keys():\n",
    "    images_with_knowns.extend(coco_2017_train.getImgIds(catIds=[_]))\n",
    "images_with_knowns = set(images_with_knowns)\n",
    "images_without_knowns = set(coco_2017_train.imgs)-images_with_knowns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_data = coco_2017_train.dataset.copy()\n",
    "new_json={}\n",
    "new_json['images']=[]\n",
    "new_json['annotations']=[]\n",
    "new_json['categories']=test_categories_info[:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets create the entries for images and annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for img_id in images_without_knowns:\n",
    "    new_json['images'].append(coco_2017_train.imgs[img_id])\n",
    "    ann_ids = coco_2017_train.getAnnIds(imgIds=[img_id])\n",
    "    for annotation in coco_2017_train.loadAnns(ids=ann_ids):\n",
    "        annotation['category_id'] = -1\n",
    "        new_json['annotations'].append(annotation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the file with mixed unknowns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(new_json, open(f\"custom_protocols/{mixed_unknowns_file_name}\", \"w\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making the WR1 protocol with number of mixed unknowns equal to knowns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding images that donot contain any of the known objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_without_knowns = list(images_without_knowns)[:len(pascal_2007_test.imgs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_data = coco_2017_train.dataset.copy()\n",
    "new_json['images']=[]\n",
    "new_json['annotations']=[]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets create the entries for images and annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for img_id in images_without_knowns:\n",
    "    new_json['images'].append(coco_2017_train.imgs[img_id])\n",
    "    ann_ids = coco_2017_train.getAnnIds(imgIds=[img_id])\n",
    "    for annotation in coco_2017_train.loadAnns(ids=ann_ids):\n",
    "        annotation['category_id'] = -1\n",
    "        new_json['annotations'].append(annotation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the file with mixed unknowns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(new_json, open(f\"custom_protocols/{WR1_mixed_unknowns_file_name}\", \"w\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
